{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "mMZQErGsLlh7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исходно в Colab очень низкая версия библиотеки xgboost. Прийдется заменить."
      ],
      "metadata": {
        "id": "prIVn5woyvLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ВНИМАНИЕ!!! Не забудьте ответить на запрос об отмене удаления\n"
      ],
      "metadata": {
        "id": "Kcd9lCVLKujC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip uninstall xgboost\n",
        "%pip install xgboost==1.6.2\n",
        "import xgboost as xgb\n",
        "xgb.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "dxk7QfIX3oaK",
        "outputId": "74461450-2bad-4c03-ddac-6a1d68f4890d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: xgboost 0.90\n",
            "Uninstalling xgboost-0.90:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost-0.90.dist-info/*\n",
            "    /usr/local/lib/python3.7/dist-packages/xgboost/*\n",
            "    /usr/local/xgboost/libxgboost.so\n",
            "Proceed (y/n)? y\n",
            "  Successfully uninstalled xgboost-0.90\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xgboost==1.6.2\n",
            "  Downloading xgboost-1.6.2-py3-none-manylinux2014_x86_64.whl (255.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 255.9 MB 49 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.2) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost==1.6.2) (1.21.6)\n",
            "Installing collected packages: xgboost\n",
            "Successfully installed xgboost-1.6.2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.6.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from tensorflow.keras.models import Model, load_model  # Импортируем модели keras: Model\n",
        "from tensorflow.keras.layers import Input, Conv2DTranspose, concatenate, Activation, SpatialDropout2D, MaxPooling2D, \\\n",
        "    AveragePooling2D, Conv2D, BatchNormalization  # Импортируем стандартные слои keras\n",
        "from tensorflow.keras import backend as K  # Импортируем модуль backend keras'а\n",
        "from tensorflow.keras.optimizers import Adam  # Импортируем оптимизатор Adam\n",
        "from tensorflow.keras import \\\n",
        "    utils  # Импортируем модуль utils библиотеки tensorflow.keras для получения OHE-представления\n",
        "from keras import regularizers\n",
        "from keras.callbacks import Callback\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import os.path\n",
        "from tqdm.auto import tqdm\n",
        "import glob\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.test import is_gpu_available\n",
        "\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost.callback import EarlyStopping\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Модуль предполагает запуск на разных устройствах. Этот блок кода как раз \n",
        "# определяет, откуда он вызван.\n",
        "Colab = True\n",
        "try:\n",
        "    from google.colab import drive\n",
        "except:\n",
        "    Colab = False\n",
        "\n",
        "if Colab:\n",
        "    from google.colab import drive\n",
        "\n",
        "    # Подключаем Google drive\n",
        "    drive.mount('/content/drive')\n",
        "    CrPath = \"/content/drive/MyDrive/Uinnopolis/\"\n",
        "\n",
        "    import sys\n",
        "    sys.path.append('/content/drive/MyDrive/Uinnopolis')\n",
        "else:\n",
        "    Acer = not os.path.exists(\"E:/Uinnopolis/\")\n",
        "    CrPath = \"C:/Uinnopolis/\" if Acer else \"E:/Uinnopolis/\"\n",
        "\n",
        "import os, glob\n",
        "from Libs import *\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ud_Juhk6290j",
        "outputId": "1d7f8b06-a0ee-4471-f31b-a6453ae792ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Алгоритм определения лучших признаков. Работает так.\n",
        "\n",
        "Сперва обучаем классификатор на тренеровочном наборе. После чего классификатор сам рассчитает рейтинг признаков.\n",
        "Сортируем его, и дальше последовательно добавляем их по одному ко входному набору, начиная с самых значимых. Если при добавлении новой позиции результат распознавания улучшается, данный признак добавляется в набор данных"
      ],
      "metadata": {
        "id": "7saDeKMBPG_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def XGSearchFeatures(SearchFtrX, SearchFtrY, X, Y, ValidX, ValidY, XTest, From = 0, InputMask = None, GPU = 0, UseMetric=\"mlogloss\"):\n",
        "    # метод обработки модели\n",
        "    def StartModel(Ft, PrintI):\n",
        "        model = XGBClassifier(learning_rate=0.03,\n",
        "                              n_estimators=50000,\n",
        "                              max_depth=6,\n",
        "                              min_child_weight=6,\n",
        "                              max_bin=100,\n",
        "                              gamma=0,\n",
        "                              subsample=0.6,\n",
        "                              colsample_bytree=0.6,\n",
        "                              reg_alpha=0.005,\n",
        "                              objective='binary:logistic',\n",
        "                              nthread=6,\n",
        "                              scale_pos_weight=1,\n",
        "                              seed=int(65),\n",
        "                              tree_method=CrMethod,\n",
        "                              random_state=65,\n",
        "                              verbose=0)\n",
        "        \n",
        "        # Call back обеспечивает своевременную остановку при начале переобучения\n",
        "        es = EarlyStopping(\n",
        "            rounds=100,\n",
        "            save_best=True,\n",
        "            maximize=False,\n",
        "            data_name=\"validation_0\",\n",
        "            metric_name=UseMetric\n",
        "        )\n",
        "\n",
        "        VX = ValidX[:, Ft]\n",
        "        eval_set = [(VX, ValidY)]\n",
        "\n",
        "        model.fit(X[:, Ft], Y, eval_metric=UseMetric, eval_set=eval_set,\n",
        "                  verbose=0, callbacks=[es])\n",
        "\n",
        "        # make predictions for test data\n",
        "        y_pred = model.predict(VX)\n",
        "\n",
        "        accuracy = accuracy_score(ValidY, y_pred)\n",
        "        print(PrintI, 'Accuracy: %.8f%%' % (accuracy * 100.0))\n",
        "\n",
        "        return accuracy, model\n",
        "\n",
        "    # задача важная. Поэтому проверяем, что все как надо\n",
        "    print(0, ValidX.shape)\n",
        "    print(1, ValidY.shape)\n",
        "    print(2, X.shape)\n",
        "    print(3, Y.shape)\n",
        "    print(GPU)\n",
        "\n",
        "    RA = [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3, 1e-2, 5e-2, 1e-1, 5e-1, 1, 5, 10, 50, 100]\n",
        "    Methods = ['exact', 'approx', 'hist']\n",
        "    CrMethod = 'exact'\n",
        "\n",
        "    if GPU:  # and CrMethod == 'hist':\n",
        "        CrMethod = 'gpu_hist'\n",
        "\n",
        "    # Для статистики просчитваем исходный набор данных, без дополнительных признаков\n",
        "    StartModel(np.arange(X.shape[-1])[-139:], 'Исходный набор признаков (временные метки и производная')\n",
        "    _a, model = StartModel(np.arange(X.shape[-1]), 'Полный набор признаков')\n",
        "    \n",
        "    # Ранжируем признаки входного сигнала по значимости\n",
        "    \n",
        "    f = model.feature_importances_ # Поличили значимость признаков\n",
        "    np.save(f'{CrPath}feature_importances.npy', f)\n",
        "    print('Ready feature_importances.npy', f.shape)\n",
        "    fInd = np.argsort(f)[::-1]\n",
        "    CrIndex = fInd.copy()\n",
        "    LastAccuracy = 0\n",
        "\n",
        "    # И теперь запускаем жадный алгоритм подбора лучших. Оставляем только те\n",
        "    # признаки, добавление которых улучшает результат \n",
        "\n",
        "    #Result = 'Temp_Result3_399.npy'\n",
        "    #From = 400\n",
        "    #LastAccuracy = 0.99\n",
        "    From = 0\n",
        "    LastAccuracy = 0\n",
        "    if not os.path.isfile(f'{CrPath}Ftr_Result.npy'):\n",
        "        Result = [0] * len(f)\n",
        "\n",
        "        i = From # даем возможность возобновиться после прерывания\n",
        "\n",
        "        for n in range(len(f) - From):\n",
        "            # считаем модель для текущего количества признаков\n",
        "            accuracy, m = StartModel(fInd[:i+1], f'{i}/{n+From}')\n",
        "\n",
        "            if LastAccuracy > accuracy:\n",
        "                # Если признак ухудшает результат - его не берем\n",
        "                fInd = np.delete(fInd, [i])\n",
        "                Result[n] = 0\n",
        "                print('Пропускаем', 'accuracy остается ', LastAccuracy)\n",
        "                \n",
        "            else:\n",
        "                LastAccuracy = accuracy\n",
        "                Result[n] = accuracy\n",
        "                i+= 1\n",
        "\n",
        "            if n % 100 == 99: # Промежуточное сохранение\n",
        "                Ft = np.array(Result)\n",
        "                np.save(f'{CrPath}Temp_Result3_{n}.npy', Ft)\n",
        "            #print(i, 'Accuracy: %.8f%%' % (accuracy * 100.0))\n",
        "\n",
        "\n",
        "        # Финальное сохранение файла восстановления\n",
        "        Ft = np.array(Result)\n",
        "        np.save(f'{CrPath}Ftr_Result.npy', Ft)\n",
        "\n",
        "    else:\n",
        "        Ft = np.load(f'{CrPath}Ftr_Result.npy')\n",
        "\n",
        "    # Теперь у нас есть значения accuracy для каждого набора фич от начала\n",
        "    # списка лучших до текущей ( за вычетом удаленных). Удаленные в этом списке \n",
        "    # помечены 0     \n",
        "\n",
        "    \n",
        "    HallIndexes = np.arange(len(Ft))\n",
        "\n",
        "    # определяем лучшие позиции\n",
        "    TheBest = np.max(Ft)\n",
        "    BestIndex = np.argmax(Ft)\n",
        "\n",
        "    fInd = fInd[Ft > 0] # массив всех непропущенных признаков\n",
        "    # Сохранили его - собственно, это главный итог работы этой задачи \n",
        "    np.save(f'{CrPath}FeatureIndex3.npy', fInd[:BestIndex])\n",
        "\n",
        "    # Но теперь немного подсоберем статистики - чтобы увидеть, что все не зря\n",
        "    \n",
        "    # Во-первых, просто убеждаемся, что все верно. Результат должен совпасть с лучшим\n",
        "    StartModel(fInd[:BestIndex], 'Финальный тест')\n",
        "\n",
        "    print('Лучший результат', TheBest)\n",
        "    print('Полный результат', CrReiting)\n"
      ],
      "metadata": {
        "id": "sN3Kucdp8j60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResX1, ResY = ReadCsv(CrPath, DelZeros=True, SortCtg=False, Train=False, RetPrc=True, PostProc=True)\n",
        "\n",
        "_x, Y = ReadCsv(CrPath, DelZeros=True, SortCtg=False, Train=True, RetPrc=True, PostProc=True)\n",
        "y_valid = Y[:100]\n",
        "y_train = Y[100:]\n",
        "\n",
        "K = 20\n",
        "y_train = np.tile(y_train, [K, 1])\n",
        "\n",
        "XValid = np.load(f'{CrPath}Input/Valid_100_FullFields.npy')\n",
        "X = np.load(f'{CrPath}Input/Train_100_FullFields.npy')\n",
        "\n",
        "ResX0, YTest = ReadCsv(CrPath, DelZeros=True, SortCtg=False, Train=False, RetPrc=True, PostProc=True)\n",
        "Ftr_Test = np.load(f'{CrPath}Input/Ftr_test.npy')\n",
        "XTest = np.concatenate((Ftr_Test, ResX0), -1)\n",
        "\n",
        "y_valid = np.tile(y_valid, [K, 1])\n",
        "\n",
        "fInd = np.load(f'{CrPath}Input/FeatureIndex0.npy')\n",
        "XTest = XTest[:, fInd]\n",
        "\n",
        "XGSearchFeatures(X, y_train[:, 1], X, y_train[:, 1], XValid, y_valid[:, 1:2], XTest = None, GPU=is_gpu_available(), UseMetric=\"mlogloss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "PymsG8lQ0wwT",
        "outputId": "09b81f59-6e30-4cd8-96d9-5af6158f299f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 (2000, 928)\n",
            "1 (2000, 1)\n",
            "2 (94600, 928)\n",
            "3 (94600,)\n",
            "True\n",
            "[11:23:50] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "Исходный набор признаков (временные метки и производная Accuracy: 96.20000000%\n",
            "[11:24:21] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "Полный набор признаков Accuracy: 96.15000000%\n",
            "Ready feature_importances.npy (928,)\n",
            "[11:25:58] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "0/0 Accuracy: 27.15000000%\n",
            "[11:26:04] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "1/1 Accuracy: 27.35000000%\n",
            "[11:26:08] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "2/2 Accuracy: 39.15000000%\n",
            "[11:26:18] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "3/3 Accuracy: 54.20000000%\n",
            "[11:26:25] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "4/4 Accuracy: 58.10000000%\n",
            "[11:26:31] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "5/5 Accuracy: 65.95000000%\n",
            "[11:26:40] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "6/6 Accuracy: 66.30000000%\n",
            "[11:26:47] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "7/7 Accuracy: 65.95000000%\n",
            "Пропускаем accuracy остается  0.663\n",
            "[11:26:56] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "7/8 Accuracy: 68.55000000%\n",
            "[11:27:05] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "8/9 Accuracy: 70.40000000%\n",
            "[11:27:13] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "9/10 Accuracy: 74.95000000%\n",
            "[11:27:21] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "10/11 Accuracy: 73.90000000%\n",
            "Пропускаем accuracy остается  0.7495\n",
            "[11:27:28] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "10/12 Accuracy: 82.20000000%\n",
            "[11:27:36] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "11/13 Accuracy: 85.10000000%\n",
            "[11:27:46] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "12/14 Accuracy: 84.55000000%\n",
            "Пропускаем accuracy остается  0.851\n",
            "[11:27:59] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "12/15 Accuracy: 86.45000000%\n",
            "[11:28:12] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "13/16 Accuracy: 87.90000000%\n",
            "[11:28:31] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "14/17 Accuracy: 90.25000000%\n",
            "[11:28:49] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "15/18 Accuracy: 89.50000000%\n",
            "Пропускаем accuracy остается  0.9025\n",
            "[11:29:05] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "15/19 Accuracy: 88.65000000%\n",
            "Пропускаем accuracy остается  0.9025\n",
            "[11:29:24] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "15/20 Accuracy: 90.50000000%\n",
            "[11:29:46] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "16/21 Accuracy: 91.75000000%\n",
            "[11:30:10] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "17/22 Accuracy: 91.65000000%\n",
            "Пропускаем accuracy остается  0.9175\n",
            "[11:30:25] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "17/23 Accuracy: 91.40000000%\n",
            "Пропускаем accuracy остается  0.9175\n",
            "[11:30:49] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "17/24 Accuracy: 90.75000000%\n",
            "Пропускаем accuracy остается  0.9175\n",
            "[11:31:10] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "17/25 Accuracy: 91.20000000%\n",
            "Пропускаем accuracy остается  0.9175\n",
            "[11:31:28] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "17/26 Accuracy: 92.95000000%\n",
            "[11:31:47] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "18/27 Accuracy: 91.20000000%\n",
            "Пропускаем accuracy остается  0.9295\n",
            "[11:32:09] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "18/28 Accuracy: 92.15000000%\n",
            "Пропускаем accuracy остается  0.9295\n",
            "[11:32:28] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "18/29 Accuracy: 93.30000000%\n",
            "[11:32:46] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/30 Accuracy: 92.35000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:33:03] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/31 Accuracy: 92.65000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:33:20] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/32 Accuracy: 92.90000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:33:41] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/33 Accuracy: 92.75000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:34:00] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/34 Accuracy: 93.20000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:34:13] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/35 Accuracy: 93.20000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:34:32] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/36 Accuracy: 92.95000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:34:48] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/37 Accuracy: 93.20000000%\n",
            "Пропускаем accuracy остается  0.933\n",
            "[11:35:08] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "19/38 Accuracy: 93.60000000%\n",
            "[11:35:26] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "20/39 Accuracy: 93.50000000%\n",
            "Пропускаем accuracy остается  0.936\n",
            "[11:35:44] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "20/40 Accuracy: 93.45000000%\n",
            "Пропускаем accuracy остается  0.936\n",
            "[11:36:00] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "20/41 Accuracy: 92.60000000%\n",
            "Пропускаем accuracy остается  0.936\n",
            "[11:36:15] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "20/42 Accuracy: 92.95000000%\n",
            "Пропускаем accuracy остается  0.936\n",
            "[11:36:33] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "20/43 Accuracy: 92.90000000%\n",
            "Пропускаем accuracy остается  0.936\n",
            "[11:36:53] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "20/44 Accuracy: 94.15000000%\n",
            "[11:37:13] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "21/45 Accuracy: 92.80000000%\n",
            "Пропускаем accuracy остается  0.9415\n",
            "[11:37:31] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "21/46 Accuracy: 93.15000000%\n",
            "Пропускаем accuracy остается  0.9415\n",
            "[11:37:50] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "21/47 Accuracy: 93.25000000%\n",
            "Пропускаем accuracy остается  0.9415\n",
            "[11:38:11] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "21/48 Accuracy: 93.70000000%\n",
            "Пропускаем accuracy остается  0.9415\n",
            "[11:38:30] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n",
            "21/49 Accuracy: 93.40000000%\n",
            "Пропускаем accuracy остается  0.9415\n",
            "[11:38:49] WARNING: ../src/learner.cc:627: \n",
            "Parameters: { \"scale_pos_weight\", \"verbose\" } might not be used.\n",
            "\n",
            "  This could be a false alarm, with some parameters getting used by language bindings but\n",
            "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
            "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0b52e36a24ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mXTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXTest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfInd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mXGSearchFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXValid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXTest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGPU\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_gpu_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUseMetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"mlogloss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-f6ce3fa0e051>\u001b[0m in \u001b[0;36mXGSearchFeatures\u001b[0;34m(SearchFtrX, SearchFtrY, X, Y, ValidX, ValidY, XTest, From, InputMask, GPU, UseMetric)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mFrom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;31m# считаем модель для текущего количества признаков\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStartModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfInd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'{i}/{n+From}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mLastAccuracy\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-f6ce3fa0e051>\u001b[0m in \u001b[0;36mStartModel\u001b[0;34m(Ft, PrintI)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         model.fit(X[:, Ft], Y, eval_metric=UseMetric, eval_set=eval_set,\n\u001b[0;32m---> 34\u001b[0;31m                   verbose=0, callbacks=[es])\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# make predictions for test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1409\u001b[0m             \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1410\u001b[0m             \u001b[0mxgb_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1411\u001b[0;31m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1412\u001b[0m         )\n\u001b[1;32m   1413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m         \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   1778\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[1;32m   1779\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1780\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m   1781\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1782\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}